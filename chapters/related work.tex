In this chapter, we outline some of the work done on benchmarks.
We also discuss some of the work done on dynamic analysis.

\section{Benchmarks}
% In the context of software development, a benchmark is a standardized set of tests that are designed to measure the performance of a system or application.
% These tests are typically used to assess the speed, scalability, and resource utilization of a given system, and can be an important tool for developers seeking to optimize their code and improve overall performance.
% When it comes to evaluating the performance of a software system, there are two primary types of benchmarks: static benchmarks and dynamic benchmarks.
% Static benchmarks involve running a predetermined set of tests on a given system or application, with fixed input parameters and test conditions. These benchmarks are useful for measuring the absolute performance of a system under a specific set of circumstances, and can be used to compare the performance of different systems or implementations against one another.
% Dynamic benchmarks involve running a set of tests that are designed to adapt and respond to the behavior of the system being tested. These benchmarks are typically more complex than static benchmarks, and are designed to simulate real-world usage scenarios and workloads.
% One of the main benefits of dynamic benchmarks is that they provide a more accurate and realistic assessment of system performance than static benchmarks.
% Because dynamic benchmarks can adapt to the behavior of the system being tested, they can capture a wider range of use cases and performance characteristics that may not be captured by static benchmarks alone.

% \textit{DaCapo Benchmark.} Traditional benchmarks, such as those developed for C, C++, and Fortran, typically focus on static properties, such as code complexity and code size.
% However, there is a need for benchmarks that can account for dynamic properties, such as memory management and garbage collection.
Dynamic benchmarks, such as the DaCapo benchmark suite, provide a more comprehensive evaluation of software systems by taking into account the interactions between architecture, compiler, virtual machine, memory management, and application. These benchmarks evaluate the performance of software systems under more realistic conditions, allowing researchers and developers to better understand how their systems will perform in the real world. \cite{DaCapo_2006}
The SPEC C++ benchmarks, including SPEC CPU2006 C++, SPEC OMP2012, and SPEC MPI2007 are designed to evaluate the performance of C++ compilers, libraries, and hardware platforms. These benchmarks are valuable for developers and researchers seeking to optimize the performance of C++ programs, as they provide insights into the performance characteristics of their code and can be used to compare the performance of different C++ compilers and libraries on different hardware platforms. \cite{SPEC_C++_2006, SPEC_OMP_2012, SPEC_MPI_2007}
While, DaCapo and SPEC C++ Benchmark provide a dynamic benchmark for Java and C++, Python does not have one. DyPyBench, overcomes this by providing a dynamic benchmark for Python.    

\section{Dynamic Analysis}
The analysis of properties of a running program is known as dynamic analysis.\cite{Ball_1999}
Dynamic analysis can be particularly useful in complex software systems, where issues may be difficult to identify or diagnose through manual testing alone.
\cite{dynamic_analysis}
TaintCheck proposes dynamic taint analysis for automatic detection and analysis of software vulnerabilities. The approach is to performs binary rewriting at run time and reliably detects most types of exploits without false positives.\cite{newsome2005dynamic}
Branch Coverage analysis counts program branch execution and outcome frequency with a single API hook. Results are stored in a dictionary mapping branch location and condition value to event occurrences. The hierarchy captures all branching events, enabling effective analysis with minimal implementation.\cite{DynaPyt2022}
DyPyBench provides a call graph analysis to generate call graphs during run-time for Python programs. 
% The first experimental study on dynamic opcode analysis of cryptomining has shown that browser-based cryptomining can be detected with accuracies up to 100\%, offering an opportunity to rapidly detect, prevent, and mitigate such attacks.\cite{Dynamic_analysis_usage}

% Dynamic analysis is a software testing technique that involves evaluating the behavior of a running program or system in real-time.
% Unlike static analysis, which involves analyzing the source code of a program without actually running it, dynamic analysis involves monitoring the behavior of a program as it runs, to identify bugs, errors, and other issues that may not be apparent from the source code alone.
% One of the primary benefits of dynamic analysis is that it allows developers to identify and diagnose issues that may be difficult or impossible to detect through static analysis alone.
% For example, dynamic analysis can be used to identify memory leaks, race conditions, and other types of concurrency issues that may not be apparent from the source code alone.
% Dynamic analysis can be particularly useful in complex software systems, where issues may be difficult to identify or diagnose through manual testing alone.
% \cite{dynamic_analysis}

% \textit{DynaPyt Framework.} DynaPyt is the first general-purpose framework for heavy-weight dynamic analysis of Python programs. DynaPyt offers a wider range of analysis hooks and features selective instrumentation and execution modification. The framework is evaluated on 9 open-source Python projects totaling 1,268,545 lines of code and shows that it preserves the semantics of the original execution. DynaPyt's running time is in line with similar frameworks designed for other languages and is faster than analyses using Python's built-in tracing API. Several analyses are implemented, including detecting memory blow-ups, taint analysis for SQL injections, and warning about runtime performance anti-patterns. Implementation of new analyses for potential use cases is simple in DynaPyt. DynaPyt provides a valuable tool for developers and researchers seeking to optimize the performance and security of Python programs through dynamic analysis. \cite{DynaPyt2022}

% While DynaPyt provides us some sample analyses, DyPyBench adds a new one to its arsenal and uses it on a number of projects. This analyses is named as Call Graph and it generates run-time call graphs for the projects in DyPyBench. 

% \section{Neural Networks for Input Prediction}
% Neural networks for code prediction involve training models to predict the input that a software program requires based on contextual information, such as user behavior, previous inputs, or external events.
% These models have potential applications in automating programming tasks and facilitating collaboration between developers with varying levels of expertise.

% \textit{LExecutor.} Executing code is important for various program analysis tasks, but it can be difficult due to missing definitions, inputs, and dependencies. LExecutor is a learning-guided approach for executing arbitrary code snippets by letting a neural model predict missing values and injecting them into the execution. For instance, LExecutor injects likely values for undefined variables and likely return values of missing functions. The approach is evaluated on Python code from popular open-source projects and code snippets from Stack Overflow. The neural model predicts realistic values with an accuracy between 80.1\% and 94.2\%, allowing LExecutor to closely mimic real executions. As a result, LExecutor successfully executes significantly more code than other techniques, covering 50.1\% of all lines compared to 4.1\% when executing the code as-is. LExecutor provides a promising approach for executing underconstrained code snippets, enabling more comprehensive and accurate program analysis. \cite{LExecutor_2023}

% With more data, the neural model can learn more complex patterns and relationships, leading to a better understanding of the underlying data distribution. DyPyBench provides this extra data for LExecutor to generalize and improve the accuracy of the model.